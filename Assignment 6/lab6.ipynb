{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df1=pd.read_csv('F:/0Sem 7/ML Lab/amazon food review dataset/Reviews.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454,) (568454,) (568454, 2)\n"
     ]
    }
   ],
   "source": [
    "score=df1.values[:,6]\n",
    "text=df1.values[:,9]\n",
    "reviews=np.vstack((score,text)).T\n",
    "print(score.shape, text.shape, reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "n=0\n",
    "for i in range(reviews.shape[0]):\n",
    "    if reviews[i,0] > 3:\n",
    "        reviews[i,0]=0 #positive review\n",
    "        p=p+1\n",
    "    else:\n",
    "        reviews[i,0]=1 #negative review\n",
    "        n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews[reviews[:,0].argsort()]   #sort by 1st column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=[]\n",
    "for i in range(5000):\n",
    "    train.append(reviews[i])\n",
    "    \n",
    "for i in range(443777,443777+5000):\n",
    "    train.append(reviews[i])\n",
    "    \n",
    "train=np.asarray(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_reviews1=np.array([0,'This is a very good product. I am very happy with this item.'])\n",
    "my_reviews2=np.array([1,'The product is very bad. I am very unsatisfied with the appearance.'])\n",
    "my_reviews3=np.array([0,'It was one if the best items i have purchased. Very good.'])\n",
    "my_reviews4=np.array([0,'All members of my family enjoyed the item. It is well thought.'])\n",
    "my_reviews5=np.array([1,'Extremely poor quality. I hated the item and so did my brothers.'])\n",
    "\n",
    "#train=np.vstack((train,my_reviews1))\n",
    "#train=np.vstack((train,my_reviews2))\n",
    "#train=np.vstack((train,my_reviews3))\n",
    "#train=np.vstack((train,my_reviews4))\n",
    "#train=np.vstack((train,my_reviews5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random as r\n",
    "test=[]\n",
    "for i in range(2000):\n",
    "    index=r.randint(0,reviews.shape[0])\n",
    "    test.append(reviews[index])\n",
    "    \n",
    "test=np.asarray(test)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test=np.vstack((test,my_reviews1))\n",
    "#test=np.vstack((test,my_reviews2))\n",
    "#test=np.vstack((test,my_reviews3))\n",
    "#test=np.vstack((test,my_reviews4))\n",
    "#test=np.vstack((test,my_reviews5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_words=[]\n",
    "for i in range(train.shape[0]):\n",
    "    train_all_words.append(train[i,1].split())\n",
    "    \n",
    "train_all_words = [item for sublist in train_all_words for item in sublist]\n",
    "\n",
    "test_all_words=[]\n",
    "for i in range(test.shape[0]):\n",
    "    test_all_words.append(test[i,1].split())\n",
    "    \n",
    "test_all_words = [item for sublist in test_all_words for item in sublist]\n",
    "\n",
    "from collections import Counter\n",
    "def common_words(words, number_of_words, reverse=False):\n",
    "    counter = Counter(words)\n",
    "    return sorted(counter, key = counter.get, reverse=reverse)[:number_of_words]\n",
    "\n",
    "train_least_common=common_words(train_all_words,200)\n",
    "train_most_common=common_words(train_all_words,200,reverse=True)\n",
    "\n",
    "test_least_common=common_words(test_all_words,200)\n",
    "test_most_common=common_words(test_all_words,200,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train.shape[0]):\n",
    "    train[i,1]=train[i,1].split()\n",
    "    \n",
    "for i in range(test.shape[0]):\n",
    "    test[i,1]=test[i,1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train.shape[0]):\n",
    "    for item in train_most_common:\n",
    "        if item in train[i,1]:\n",
    "            train[i,1].remove(item)\n",
    "    for item in train_least_common:\n",
    "        if item in train[i,1]:\n",
    "            train[i,1].remove(item)\n",
    "            \n",
    "for i in range(test.shape[0]):\n",
    "    for item in test_most_common:\n",
    "        if item in test[i,1]:\n",
    "            test[i,1].remove(item)\n",
    "    for item in test_least_common:\n",
    "        if item in test[i,1]:\n",
    "            test[i,1].remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train.shape[0]):\n",
    "    train[i,1]=\" \".join(train[i,1])\n",
    "    \n",
    "for i in range(test.shape[0]):\n",
    "    test[i,1]=\" \".join(test[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs=[]\n",
    "test_docs=[]\n",
    "train_label=[]\n",
    "test_label=[]\n",
    "for i in range(train.shape[0]):\n",
    "    train_docs.append(train[i,1])\n",
    "    train_label.append(train[i,0])\n",
    "    \n",
    "for i in range(test.shape[0]):\n",
    "    test_docs.append(test[i,1])\n",
    "    test_label.append(test[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "#integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(train_docs)\n",
    "\n",
    "#print(encoded_docs)\n",
    "#pad documents to a max length of 4 words\n",
    "\n",
    "max_length = 100\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "#print(padded_docs)\n",
    "#load the whole embedding into memory\n",
    "\n",
    "embeddings_index = dict()\n",
    "f = open('F:/0Sem 7/ML Lab/glove/glove.6B.100d.txt',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "#print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "#create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19814, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#define model\n",
    "model = Sequential()\n",
    "e = tf.keras.layers.Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=100, trainable=False)\n",
    "model.add(e)\n",
    "model.add(layers.LSTM(64, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 100)          1981400   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,023,705\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 1,981,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 100, 100)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label=np.asarray(train_label)\n",
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t1 = Tokenizer()\n",
    "t1.fit_on_texts(test_docs)\n",
    "vocab_size1 = len(t1.word_index) + 1\n",
    "#integer encode the documents\n",
    "encoded_docs1 = t1.texts_to_sequences(test_docs)\n",
    "\n",
    "#print(encoded_docs)\n",
    "#pad documents to a max length of 4 words\n",
    "\n",
    "max_length1 = 100\n",
    "padded_docs1 = pad_sequences(encoded_docs1, maxlen=max_length1, padding='post')\n",
    "test_label=np.asarray(test_label)\n",
    "#print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 44s 4ms/sample - loss: 0.7321 - accuracy: 0.5237 - val_loss: 0.6946 - val_accuracy: 0.7195\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 0.8181 - accuracy: 0.5321 - val_loss: 0.6902 - val_accuracy: 0.7300\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 0.6892 - accuracy: 0.5289 - val_loss: 0.6926 - val_accuracy: 0.7140\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 0.6883 - accuracy: 0.5290 - val_loss: 0.6959 - val_accuracy: 0.7105\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 1182558.7550 - accuracy: 0.5261 - val_loss: 0.6851 - val_accuracy: 0.7265\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 36s 4ms/sample - loss: 0.6897 - accuracy: 0.5301 - val_loss: 0.6931 - val_accuracy: 0.7120\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 38s 4ms/sample - loss: 0.6895 - accuracy: 0.5295 - val_loss: 0.6942 - val_accuracy: 0.7130\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 0.6894 - accuracy: 0.5285 - val_loss: 0.6957 - val_accuracy: 0.7120\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 44s 4ms/sample - loss: 0.6892 - accuracy: 0.5277 - val_loss: 0.6954 - val_accuracy: 0.7140\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 46s 5ms/sample - loss: 0.6891 - accuracy: 0.5271 - val_loss: 0.6956 - val_accuracy: 0.7140\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 46s 5ms/sample - loss: 0.6890 - accuracy: 0.5281 - val_loss: 0.6945 - val_accuracy: 0.7135\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6889 - accuracy: 0.5276 - val_loss: 0.6950 - val_accuracy: 0.7135\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 45s 5ms/sample - loss: 0.6888 - accuracy: 0.5272 - val_loss: 0.6957 - val_accuracy: 0.7135\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6888 - accuracy: 0.5275 - val_loss: 0.6950 - val_accuracy: 0.7130\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6887 - accuracy: 0.5271 - val_loss: 0.6943 - val_accuracy: 0.7135\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6886 - accuracy: 0.5264 - val_loss: 0.6946 - val_accuracy: 0.7130\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6885 - accuracy: 0.5263 - val_loss: 0.6948 - val_accuracy: 0.7130\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6884 - accuracy: 0.5268 - val_loss: 0.6942 - val_accuracy: 0.7140\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6883 - accuracy: 0.5275 - val_loss: 0.6945 - val_accuracy: 0.7140\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6882 - accuracy: 0.5269 - val_loss: 0.6937 - val_accuracy: 0.7145\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 0.6881 - accuracy: 0.5276 - val_loss: 0.6925 - val_accuracy: 0.7155\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 42s 4ms/sample - loss: 0.6880 - accuracy: 0.5280 - val_loss: 0.6918 - val_accuracy: 0.7160\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 42s 4ms/sample - loss: 0.6879 - accuracy: 0.5286 - val_loss: 0.6949 - val_accuracy: 0.7130\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 42s 4ms/sample - loss: 0.6878 - accuracy: 0.5299 - val_loss: 0.6950 - val_accuracy: 0.7135\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 42s 4ms/sample - loss: 0.6877 - accuracy: 0.5294 - val_loss: 0.6926 - val_accuracy: 0.7145\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 42s 4ms/sample - loss: 0.6876 - accuracy: 0.5304 - val_loss: 0.6938 - val_accuracy: 0.7150\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 42s 4ms/sample - loss: 0.6875 - accuracy: 0.5312 - val_loss: 0.6949 - val_accuracy: 0.7140\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 45s 5ms/sample - loss: 0.6874 - accuracy: 0.5303 - val_loss: 0.6956 - val_accuracy: 0.7135\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 0.6873 - accuracy: 0.5316 - val_loss: 0.6951 - val_accuracy: 0.7135\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 44s 4ms/sample - loss: 0.6872 - accuracy: 0.5317 - val_loss: 0.6948 - val_accuracy: 0.7145\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6870 - accuracy: 0.5313 - val_loss: 0.6949 - val_accuracy: 0.7140\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 44s 4ms/sample - loss: 0.6869 - accuracy: 0.5311 - val_loss: 0.6944 - val_accuracy: 0.7135\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6868 - accuracy: 0.5322 - val_loss: 0.6949 - val_accuracy: 0.7145\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6867 - accuracy: 0.5319 - val_loss: 0.6964 - val_accuracy: 0.7145\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6865 - accuracy: 0.5325 - val_loss: 0.6962 - val_accuracy: 0.7165\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6864 - accuracy: 0.5315 - val_loss: 0.6974 - val_accuracy: 0.7150\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 45s 4ms/sample - loss: 0.6863 - accuracy: 0.5321 - val_loss: 0.6972 - val_accuracy: 0.7145\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 45s 5ms/sample - loss: 107945.4403 - accuracy: 0.5191 - val_loss: 0.6947 - val_accuracy: 0.7085\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 44s 4ms/sample - loss: 4.3652 - accuracy: 0.5283 - val_loss: 0.6957 - val_accuracy: 0.7075\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 44s 4ms/sample - loss: 1.9525 - accuracy: 0.5288 - val_loss: 0.6972 - val_accuracy: 0.7055\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 44s 4ms/sample - loss: 1.8938 - accuracy: 0.5292 - val_loss: 0.6977 - val_accuracy: 0.7045\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.8593 - accuracy: 0.5289 - val_loss: 0.6969 - val_accuracy: 0.7055\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.8386 - accuracy: 0.5288 - val_loss: 0.6982 - val_accuracy: 0.7045\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.8131 - accuracy: 0.5299 - val_loss: 0.6978 - val_accuracy: 0.7040\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.7947 - accuracy: 0.5294 - val_loss: 0.6962 - val_accuracy: 0.7055\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.7758 - accuracy: 0.5295 - val_loss: 0.6948 - val_accuracy: 0.7075\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.7580 - accuracy: 0.5294 - val_loss: 0.6950 - val_accuracy: 0.7080\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.7402 - accuracy: 0.5299 - val_loss: 0.6960 - val_accuracy: 0.7075\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.7218 - accuracy: 0.5303 - val_loss: 0.6968 - val_accuracy: 0.7045\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 43s 4ms/sample - loss: 1.7033 - accuracy: 0.5296 - val_loss: 0.6964 - val_accuracy: 0.7065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d37529e908>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, train_label, validation_data=(padded_docs1,test_label), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2nd LSTM Model'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"2nd LSTM Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 100)          1981400   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 64)           42240     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,122,585\n",
      "Trainable params: 141,185\n",
      "Non-trainable params: 1,981,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model1 = Sequential()\n",
    "e = tf.keras.layers.Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=100, trainable=False)\n",
    "model1.add(e)\n",
    "model1.add(layers.LSTM(64, activation='tanh', return_sequences=True))\n",
    "model1.add(layers.LSTM(128, activation='tanh', return_sequences=False))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 22s 2ms/sample - loss: 0.6915 - accuracy: 0.5237 - val_loss: 0.7199 - val_accuracy: 0.2175\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 8s 772us/sample - loss: 0.6878 - accuracy: 0.5327 - val_loss: 0.7133 - val_accuracy: 0.2170\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 8s 763us/sample - loss: 0.6899 - accuracy: 0.5167 - val_loss: 0.6976 - val_accuracy: 0.7000\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 8s 771us/sample - loss: 0.6875 - accuracy: 0.5399 - val_loss: 0.6200 - val_accuracy: 0.6810\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 8s 782us/sample - loss: 0.6728 - accuracy: 0.5756 - val_loss: 0.5747 - val_accuracy: 0.7820\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 8s 781us/sample - loss: 0.6917 - accuracy: 0.5137 - val_loss: 0.6782 - val_accuracy: 0.7025\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 8s 763us/sample - loss: 0.6865 - accuracy: 0.5494 - val_loss: 0.6506 - val_accuracy: 0.6210\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 8s 792us/sample - loss: 0.6609 - accuracy: 0.6034 - val_loss: 0.8445 - val_accuracy: 0.5090\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 8s 770us/sample - loss: 0.5598 - accuracy: 0.7277 - val_loss: 0.6652 - val_accuracy: 0.6505\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 8s 760us/sample - loss: 0.4942 - accuracy: 0.7688 - val_loss: 0.7371 - val_accuracy: 0.6215\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 8s 766us/sample - loss: 0.4598 - accuracy: 0.7943 - val_loss: 0.7640 - val_accuracy: 0.5925\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 8s 771us/sample - loss: 0.4308 - accuracy: 0.8110 - val_loss: 1.1489 - val_accuracy: 0.3905\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 8s 765us/sample - loss: 0.4057 - accuracy: 0.8267 - val_loss: 1.0307 - val_accuracy: 0.4605\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 8s 767us/sample - loss: 0.3884 - accuracy: 0.8351 - val_loss: 1.0522 - val_accuracy: 0.4435\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 8s 769us/sample - loss: 0.3589 - accuracy: 0.8499 - val_loss: 1.1407 - val_accuracy: 0.4835\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 8s 760us/sample - loss: 0.3316 - accuracy: 0.8645 - val_loss: 1.0593 - val_accuracy: 0.5225\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 8s 768us/sample - loss: 0.3019 - accuracy: 0.8808 - val_loss: 1.0885 - val_accuracy: 0.4935\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 8s 758us/sample - loss: 0.2826 - accuracy: 0.8900 - val_loss: 1.3534 - val_accuracy: 0.4330\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 8s 768us/sample - loss: 0.2531 - accuracy: 0.9037 - val_loss: 1.0157 - val_accuracy: 0.5480\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 8s 769us/sample - loss: 0.2273 - accuracy: 0.9170 - val_loss: 1.4197 - val_accuracy: 0.4075\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 8s 771us/sample - loss: 0.2101 - accuracy: 0.9229 - val_loss: 1.2663 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 8s 767us/sample - loss: 0.1848 - accuracy: 0.9362 - val_loss: 1.4215 - val_accuracy: 0.5100\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 8s 764us/sample - loss: 0.1666 - accuracy: 0.9421 - val_loss: 1.6215 - val_accuracy: 0.4750\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 8s 758us/sample - loss: 0.1408 - accuracy: 0.9531 - val_loss: 1.5412 - val_accuracy: 0.4960\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 8s 765us/sample - loss: 0.1201 - accuracy: 0.9625 - val_loss: 1.7058 - val_accuracy: 0.5170\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 8s 762us/sample - loss: 0.1078 - accuracy: 0.9681 - val_loss: 1.6678 - val_accuracy: 0.5105\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 8s 761us/sample - loss: 0.0966 - accuracy: 0.9732 - val_loss: 1.8861 - val_accuracy: 0.4620\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 8s 766us/sample - loss: 0.1002 - accuracy: 0.9708 - val_loss: 1.8941 - val_accuracy: 0.4535\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 8s 751us/sample - loss: 0.0820 - accuracy: 0.9764 - val_loss: 1.9777 - val_accuracy: 0.5225\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 8s 754us/sample - loss: 0.0807 - accuracy: 0.9765 - val_loss: 1.9406 - val_accuracy: 0.5030\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 8s 773us/sample - loss: 0.0661 - accuracy: 0.9835 - val_loss: 2.3690 - val_accuracy: 0.4640\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 8s 753us/sample - loss: 0.0730 - accuracy: 0.9803 - val_loss: 2.3468 - val_accuracy: 0.4550\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 8s 769us/sample - loss: 0.0681 - accuracy: 0.9810 - val_loss: 2.8023 - val_accuracy: 0.4205\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 8s 760us/sample - loss: 0.0555 - accuracy: 0.9856 - val_loss: 1.9352 - val_accuracy: 0.5555\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 8s 765us/sample - loss: 0.0551 - accuracy: 0.9862 - val_loss: 2.7771 - val_accuracy: 0.4595\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 8s 756us/sample - loss: 0.0581 - accuracy: 0.9839 - val_loss: 2.5725 - val_accuracy: 0.4355\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 8s 765us/sample - loss: 0.0553 - accuracy: 0.9865 - val_loss: 2.2702 - val_accuracy: 0.4945\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 8s 767us/sample - loss: 0.0516 - accuracy: 0.9873 - val_loss: 2.0878 - val_accuracy: 0.5675\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 8s 764us/sample - loss: 0.0477 - accuracy: 0.9888 - val_loss: 2.3024 - val_accuracy: 0.4635\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 8s 758us/sample - loss: 0.0405 - accuracy: 0.9909 - val_loss: 2.1560 - val_accuracy: 0.5210\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 8s 755us/sample - loss: 0.0468 - accuracy: 0.9885 - val_loss: 2.7752 - val_accuracy: 0.4845\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 8s 762us/sample - loss: 0.0525 - accuracy: 0.9874 - val_loss: 2.0286 - val_accuracy: 0.5285\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 8s 765us/sample - loss: 0.0485 - accuracy: 0.9872 - val_loss: 2.4182 - val_accuracy: 0.4625\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 8s 757us/sample - loss: 0.0387 - accuracy: 0.9905 - val_loss: 2.7738 - val_accuracy: 0.4720\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 8s 760us/sample - loss: 0.0432 - accuracy: 0.9888 - val_loss: 2.6603 - val_accuracy: 0.4860\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 8s 763us/sample - loss: 0.0480 - accuracy: 0.9869 - val_loss: 2.4836 - val_accuracy: 0.4935\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 8s 750us/sample - loss: 0.0406 - accuracy: 0.9898 - val_loss: 2.2144 - val_accuracy: 0.5275\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 8s 752us/sample - loss: 0.0392 - accuracy: 0.9910 - val_loss: 2.8742 - val_accuracy: 0.4765\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 8s 754us/sample - loss: 0.0441 - accuracy: 0.9875 - val_loss: 2.7932 - val_accuracy: 0.4365\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 8s 756us/sample - loss: 0.0406 - accuracy: 0.9890 - val_loss: 2.5642 - val_accuracy: 0.5135\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history1=model1.fit(padded_docs, train_label, validation_data=(padded_docs1,test_label), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3rd LSTM Model'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"3rd LSTM Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 100)          1981400   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 100, 64)           42240     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,122,585\n",
      "Trainable params: 141,185\n",
      "Non-trainable params: 1,981,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "model2 = Sequential()\n",
    "e = tf.keras.layers.Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=100, trainable=False)\n",
    "model2.add(e)\n",
    "model2.add(layers.LSTM(64, activation='relu', return_sequences=True))\n",
    "model2.add(layers.LSTM(128, activation='relu', return_sequences=False))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 84s 8ms/sample - loss: 743415.0260 - accuracy: 0.5231 - val_loss: 0.6745 - val_accuracy: 0.7830\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 83s 8ms/sample - loss: 0.6986 - accuracy: 0.5113 - val_loss: 0.6883 - val_accuracy: 0.7220\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 83s 8ms/sample - loss: 0.7044 - accuracy: 0.5229 - val_loss: 0.6817 - val_accuracy: 0.7145\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 83s 8ms/sample - loss: 0.6919 - accuracy: 0.5257 - val_loss: 0.6896 - val_accuracy: 0.7000\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 1.1787 - accuracy: 0.5216 - val_loss: 0.7101 - val_accuracy: 0.2170\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 0.6919 - accuracy: 0.5039 - val_loss: 0.6997 - val_accuracy: 0.2195\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 132861716.1617 - accuracy: 0.5116 - val_loss: 0.6980 - val_accuracy: 0.7015\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 0.6907 - accuracy: 0.5238 - val_loss: 0.6953 - val_accuracy: 0.7015\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 0.6900 - accuracy: 0.5240 - val_loss: 0.6903 - val_accuracy: 0.7035\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 0.6905 - accuracy: 0.5234 - val_loss: 0.6935 - val_accuracy: 0.7010\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6947 - val_accuracy: 0.7015\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 0.6901 - accuracy: 0.5230 - val_loss: 0.6941 - val_accuracy: 0.7010\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 0.6900 - accuracy: 0.5234 - val_loss: 0.6936 - val_accuracy: 0.7010\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 0.6898 - accuracy: 0.5240 - val_loss: 0.6946 - val_accuracy: 0.7010\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 0.6897 - accuracy: 0.5243 - val_loss: 0.6935 - val_accuracy: 0.7020\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 0.6895 - accuracy: 0.5238 - val_loss: 0.6946 - val_accuracy: 0.7015\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 2219.4073 - accuracy: 0.5247 - val_loss: 0.6858 - val_accuracy: 0.7165\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 0.6917 - accuracy: 0.5248 - val_loss: 0.6913 - val_accuracy: 0.7015\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 0.7319 - accuracy: 0.5250 - val_loss: 0.6925 - val_accuracy: 0.7015\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 0.6916 - accuracy: 0.5269 - val_loss: 0.6909 - val_accuracy: 0.7025\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 0.6915 - accuracy: 0.5240 - val_loss: 0.6939 - val_accuracy: 0.7015\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 0.6941 - accuracy: 0.5248 - val_loss: 0.6931 - val_accuracy: 0.7020\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 0.6906 - accuracy: 0.5245 - val_loss: 0.6918 - val_accuracy: 0.7030\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 0.6905 - accuracy: 0.5234 - val_loss: 0.6920 - val_accuracy: 0.7030\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6924 - val_accuracy: 0.7025\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 3560293317573.9771 - accuracy: 0.5086 - val_loss: 72521689.7920 - val_accuracy: 0.4815\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 23413463.7744 - accuracy: 0.4896 - val_loss: 21862507.1935 - val_accuracy: 0.5440\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 5712983.1109 - accuracy: 0.5035 - val_loss: 2032953.6720 - val_accuracy: 0.2720\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 1086407.4026 - accuracy: 0.4926 - val_loss: 462992.1095 - val_accuracy: 0.5335\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 487807.4272 - accuracy: 0.5097 - val_loss: 489759.5040 - val_accuracy: 0.5615\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 1048917.8637 - accuracy: 0.5057 - val_loss: 1359001.6180 - val_accuracy: 0.5555\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 904459.3219 - accuracy: 0.5084 - val_loss: 508302.2320 - val_accuracy: 0.4980\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 420447.0737 - accuracy: 0.5090 - val_loss: 389416.1360 - val_accuracy: 0.4650\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 576791.7860 - accuracy: 0.5083 - val_loss: 599389.5399 - val_accuracy: 0.5490\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 448279.3773 - accuracy: 0.5079 - val_loss: 218158.6864 - val_accuracy: 0.5225\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 329771.5841 - accuracy: 0.5005 - val_loss: 255775.6389 - val_accuracy: 0.4800\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 299713.4214 - accuracy: 0.5110 - val_loss: 366722.2171 - val_accuracy: 0.5855\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 506923.3443 - accuracy: 0.5081 - val_loss: 404982.8723 - val_accuracy: 0.6000\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 404571.6474 - accuracy: 0.4977 - val_loss: 282700.5649 - val_accuracy: 0.5685\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 293064.6388 - accuracy: 0.5054 - val_loss: 332437.6422 - val_accuracy: 0.4520\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 276528.9492 - accuracy: 0.5219 - val_loss: 223187.4139 - val_accuracy: 0.5540\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 156078.3229 - accuracy: 0.5041 - val_loss: 124955.1655 - val_accuracy: 0.5630\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 157497.4617 - accuracy: 0.5075 - val_loss: 602948.0615 - val_accuracy: 0.5400\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 79s 8ms/sample - loss: 140568.8114 - accuracy: 0.5126 - val_loss: 223917.5466 - val_accuracy: 0.6710\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 81s 8ms/sample - loss: 71527.2520 - accuracy: 0.5039 - val_loss: 54877.0396 - val_accuracy: 0.5645\n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 80s 8ms/sample - loss: 57211.6238 - accuracy: 0.5105 - val_loss: 3545.0209 - val_accuracy: 0.4135\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 86s 9ms/sample - loss: 6487.3033 - accuracy: 0.5169 - val_loss: 2188.7425 - val_accuracy: 0.5685\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 83s 8ms/sample - loss: 6410.6560 - accuracy: 0.5144 - val_loss: 2046.3632 - val_accuracy: 0.5760\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 5760.6075 - accuracy: 0.5233 - val_loss: 2386.5145 - val_accuracy: 0.6840\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 82s 8ms/sample - loss: 8136.9675 - accuracy: 0.5097 - val_loss: 2409.3409 - val_accuracy: 0.6855\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history2=model2.fit(padded_docs, train_label, validation_data=(padded_docs1,test_label), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
